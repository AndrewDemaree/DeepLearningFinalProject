{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import itertools\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for custon input dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = sorted(os.listdir(image_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        state, image_index, subimage_index = img_name.split('_')[:3]\n",
    "\n",
    "        # Construct image and mask file paths\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        mask_name = f\"{state}_raster_mask_{image_index}.tiff\"\n",
    "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "\n",
    "        # Load image and mask\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified DeepLabV3+ with atrous convolution\n",
    "class ModifiedDeepLabV3Plus(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels, num_levels, dilation):\n",
    "        super(ModifiedDeepLabV3Plus, self).__init__()\n",
    "        self.pyramid_pooling = PyramidPooling(in_channels, num_levels=num_levels)\n",
    "        self.model = segmentation.deeplabv3plus_xception(pretrained=False, num_classes=num_classes, aux_loss=None)\n",
    "        \n",
    "        #Adds atrous convolution to convolutional layer in xception backbone\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                module.dilation = dilation\n",
    "                \n",
    "    def forward(self, x):\n",
    "        return self.model(x)['out']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, num_levels, kernel_size):\n",
    "        super(PyramidPooling, self).__init__()\n",
    "        \n",
    "        self.num_levels = num_levels\n",
    "        \n",
    "        #number of filters\n",
    "        out_channels = in_channels // num_levels\n",
    "        \n",
    "        #pooling layers\n",
    "        self.pooling_layers = nn.ModuleList()\n",
    "        for i in range(num_levels):\n",
    "            self.pooling_layers.append(nn.AdaptiveAvgPool2d((i+1, i+1)))\n",
    "        \n",
    "        #convolutional layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for i in range(num_levels):\n",
    "            self.conv_layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size))\n",
    "     \n",
    "    #Forward Step   \n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        \n",
    "        #Pooling and convolution operations per level\n",
    "        for i in range(self.num_levels):\n",
    "            pooled = self.pooling_layers[i](x)\n",
    "            conv_out = self.conv_layers[i](pooled)\n",
    "            upsampled = F.interpolate(conv_out, size=x.size()[2:], mode='bilinear', align_corners=False)\n",
    "            features.append(upsampled)\n",
    "        \n",
    "        output = torch.cat(features, dim=1)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabV3PlusModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes, in_channels, learning_rate, lr_step_size, lr_gamma):\n",
    "        super(DeepLabV3PlusModel, self).__init__()\n",
    "\n",
    "        self.model = ModifiedDeepLabV3Plus(num_classes, in_channels)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_step_size = lr_step_size\n",
    "        self.lr_gamma = lr_gamma\n",
    "    \n",
    "    #Forwatd Step   \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    #Model Training\n",
    "    def training_step(self, batch):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        \n",
    "        loss_ce = self.criterion(outputs, masks)\n",
    "        loss_fwio = self.calculate_fwio_loss(outputs, masks)\n",
    "        loss = loss_ce + loss_fwio\n",
    "        \n",
    "        self.log('train_loss_ce', loss_ce)\n",
    "        self.log('train_loss_fwio', loss_fwio)\n",
    "        self.log('train_loss_total', loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    #Model Validation\n",
    "    def validation_step(self, batch):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        \n",
    "        loss_ce = self.criterion(outputs, masks)\n",
    "        loss_fwio = self.calculate_fwio_loss(outputs, masks)\n",
    "        loss = loss_ce + loss_fwio\n",
    "        iou = self.calculate_iou(outputs, masks)\n",
    "\n",
    "        self.log('val_loss_ce', loss_ce)\n",
    "        self.log('val_loss_fwio', loss_fwio)\n",
    "        self.log('val_loss_total', loss)\n",
    "        self.log('val_iou', iou)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = StepLR(optimizer, step_size=self.lr_step_size, gamma=self.lr_gamma)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def calculate_fwio_loss(self, outputs, masks):\n",
    "        #calculates loss\n",
    "        num_classes = outputs.size(1)\n",
    "        fwio_loss = 0.0\n",
    "        \n",
    "        for cls in range(num_classes):\n",
    "            pred = outputs[:, cls, :, :]\n",
    "            gt = (masks == cls).float()\n",
    "            \n",
    "            intersection = torch.sum(pred * gt)\n",
    "            union = torch.sum(pred) + torch.sum(gt) - intersection\n",
    "            \n",
    "            fwio_loss += (intersection / union)\n",
    "        \n",
    "        fwio_loss /= num_classes\n",
    "        return 1.0 - fwio_loss\n",
    "    \n",
    "    def calculate_iou(self, outputs, masks):\n",
    "        #Calculates intersection over union\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        intersection = torch.sum(preds & masks)\n",
    "        union = torch.sum(preds | masks)\n",
    "        iou = intersection.float() / union.float()\n",
    "        return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_dir = '/Users/andrew/Documents/Spring 2023/Intro to Deep Learning/trail_data/image_dir'\n",
    "mask_dir = '/Users/andrew/Documents/Spring 2023/Intro to Deep Learning/trail_data/mask_dir'\n",
    "\n",
    "#Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#Instance of Dataset custom class\n",
    "dataset = CustomDataset(image_dir, mask_dir, transform=transform)\n",
    "\n",
    "#Dataset Splitting \n",
    "train_ratio = 0.8  # Ratio for training data\n",
    "train_data, val_data = train_test_split(dataset, train_size=train_ratio, test_size=1 - train_ratio)\n",
    "\n",
    "#DataLoaders for training and validation\n",
    "train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=4, shuffle=True)\n",
    "\n",
    "#Grid Search\n",
    "# Hyperparameter Ranges\n",
    "learning_rate_range = [1e-5, 1e-4, 1e-3]\n",
    "batch_size_range = [16, 32, 64, 128, 256]\n",
    "epochs_range = [50, 100, 150, 200]\n",
    "network_depth_range = [16, 34, 50, 101, 152]\n",
    "num_levels_range = [2, 3, 4, 5]\n",
    "dilation_range = [(1, 1), (2, 2), (4, 4)]\n",
    "lr_step_size_range = [10, 20, 30]\n",
    "lr_gamma_range = [0.1, 0.5, 0.9]\n",
    "kernel_size_range = [2, 3, 4, 5]\n",
    "\n",
    "#validation metrics and models for each hyperparameter\n",
    "validation_metric_dict = {\n",
    "    'learning_rate': ['mean_intersection_over_union', 'loss'],\n",
    "    'batch_size': ['mean_intersection_over_union', 'loss'],\n",
    "    'epochs': ['mean_intersection_over_union', 'loss'],\n",
    "    'network_depth': ['mean_intersection_over_union', 'loss'],\n",
    "    'num_levels': ['mean_intersection_over_union', 'loss'],\n",
    "    'dilation': ['mean_intersection_over_union', 'loss'],\n",
    "    'lr_stepsize': ['mean_intersection_over_union', 'loss'], \n",
    "    'lr_gamma': ['mean_intersection_over_union', 'loss'],  \n",
    "    'kernel_size': ['mean_intersection_over_union', 'loss'] \n",
    "}\n",
    "\n",
    "model_dict = {\n",
    "    'learning_rate': ['DeepLabV3+'],\n",
    "    'batch_size': ['DeepLabV3+'],\n",
    "    'epochs': ['DeepLabV3+'],\n",
    "    'network_depth': ['DeepLabV3+'],\n",
    "    'num_levels': ['DeepLabV3+'],\n",
    "    'dilation': ['DeepLabV3+'],\n",
    "    'lr_stepsize': ['DeepLabV3+'], \n",
    "    'lr_gamma': ['DeepLabV3+'], \n",
    "    'kernel_size': ['DeepLabV3+']  \n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_iou = float('inf')\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for learning_rate, batch_size, epochs, network_depth, num_levels, dilation, lr_step_size, lr_gamma, kernel_size in itertools.product(\n",
    "    learning_rate_range, batch_size_range, epochs_range, network_depth_range,\n",
    "    num_levels_range, dilation_range, lr_step_size_range, lr_gamma_range, kernel_size_range\n",
    "):\n",
    "    #DeepLabV3PlusModel\n",
    "    num_classes = 2  # Trail or not trail\n",
    "    in_channels = 1  # Because each channel of the normalized image was saved each image only has one channel\n",
    "    \n",
    "    model = DeepLabV3PlusModel(num_classes, in_channels)\n",
    "\n",
    "    # Assign number of levels and dilation rate\n",
    "    model.model.pyramid_pooling.num_levels = num_levels\n",
    "    for name, module in model.model.model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            module.dilation = dilation\n",
    "    \n",
    "    #optimizer and scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n",
    "    \n",
    "    #Training\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_images, batch_masks in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_images)\n",
    "            loss_ce = model.criterion(outputs, batch_masks)\n",
    "            loss_fwio = model.calculate_fwio_loss(outputs, batch_masks)\n",
    "            loss = loss_ce + loss_fwio\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        #Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        intersection = 0\n",
    "        union = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_masks in val_dataloader:\n",
    "                outputs = model(batch_images)\n",
    "                loss_ce = model.criterion(outputs, batch_masks)\n",
    "                loss_fwio = model.calculate_fwio_loss(outputs, batch_masks)\n",
    "                loss = loss_ce + loss_fwio\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                #Calculate intersection and union\n",
    "                predicted_masks = torch.argmax(outputs, dim=1)\n",
    "                intersection += torch.sum(predicted_masks * batch_masks)\n",
    "                union += torch.sum(predicted_masks) + torch.sum(batch_masks) - intersection\n",
    "\n",
    "        #Loss\n",
    "        val_loss /= len(val_dataloader)\n",
    "\n",
    "        #Intersection over Union\n",
    "        iou = intersection / union\n",
    "\n",
    "        # Log losses and IoU\n",
    "        print(f\"Epoch {epoch + 1} - Train Loss: {loss.item()} - Val Loss: {val_loss} - IoU: {iou}\")\n",
    "\n",
    "# Check if the current hyperparameters result in the best validation loss\n",
    "if val_loss < best_val_loss:\n",
    "    best_val_loss = val_loss\n",
    "    best_hyperparameters_loss = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size,\n",
    "        'epochs': epochs,\n",
    "        'network_depth': network_depth,\n",
    "        'num_levels': num_levels,\n",
    "        'dilation': dilation,\n",
    "        'lr_step_size': lr_step_size,\n",
    "        'lr_gamma': lr_gamma,\n",
    "        'kernel_size': kernel_size\n",
    "    }\n",
    "\n",
    "# Check if the current hyperparameters result in the best IoU\n",
    "if iou > best_val_iou:\n",
    "    best_val_iou = iou\n",
    "    best_hyperparameters_iou = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size,\n",
    "        'epochs': epochs,\n",
    "        'network_depth': network_depth,\n",
    "        'num_levels': num_levels,\n",
    "        'dilation': dilation,\n",
    "        'lr_step_size': lr_step_size,\n",
    "        'lr_gamma': lr_gamma,\n",
    "        'kernel_size': kernel_size\n",
    "    }\n",
    "\n",
    "\n",
    "# Print the best hyperparameters and validation loss based on loss\n",
    "print(\"Best Hyperparameters (based on Loss):\")\n",
    "print(best_hyperparameters_loss)\n",
    "print(\"Best Validation Loss:\")\n",
    "print(best_val_loss)\n",
    "\n",
    "# Print the best hyperparameters and validation loss based on IoU\n",
    "print(\"Best Hyperparameters (based on IoU):\")\n",
    "print(best_hyperparameters_iou)\n",
    "print(\"Best Intersection over Union (IoU):\")\n",
    "print(best_val_iou)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
